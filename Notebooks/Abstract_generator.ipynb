{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split our text in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_text(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    filedata = file.readlines()\n",
    "    story = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "    for sentence in story:\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build similarity sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sentence1, sentence2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "    sentence1 = [word.lower() for word in sentence1]\n",
    "    sentence2 = [word.lower() for word in sentence2]\n",
    "    all_words = list(set(sentence1 + sentence2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    \n",
    "    for word in sentence1:\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(word)] += 1\n",
    " \n",
    "    for word in sentence2:\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(word)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for index1 in range(len(sentences)):\n",
    "        for index2 in range(len(sentences)):\n",
    "            if index1 == index2: \n",
    "                continue \n",
    "            similarity_matrix[index1][index2] = sentence_similarity(sentences[index1], sentences[index2], stop_words)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a rank based on matrix similarity & choose N best sentences for abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alfred is at a loss, and Matuschek avoids any explanation, finally telling Alfred that it would be best if he left', 'Alfred and Klara are getting ready to leave, and she has another date with her mystery pen pal, but Alfred delays her with a few questions', 'Later, as she is resting at home, Alfred pays her a visit, and while he is there her aunt brings her another letter from her secret pen pal that explains his not being at the meeting because he saw her there with Alfred']\n"
     ]
    }
   ],
   "source": [
    "def generate_abstract(file_name, nb_sentence):\n",
    "    stop_words = stopwords.words('english')\n",
    "    resume_text = []\n",
    "    \n",
    "    sentences = sentence_text(file_name)\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "    sentence_similarity_graph = networkx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = networkx.pagerank(sentence_similarity_graph)\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)       \n",
    "    for i in range(nb_sentence):\n",
    "        resume_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "    print(resume_text)\n",
    "\n",
    "generate_abstract( \"test.txt\",3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
